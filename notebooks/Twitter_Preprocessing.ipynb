{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e20db6e",
   "metadata": {},
   "source": [
    "## Airline Tweets pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "547ffaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import nltk\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import re\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import spacy\n",
    "from spacy.lang.en import English\n",
    "from nltk import word_tokenize, pos_tag, ne_chunk\n",
    "from autocorrect import Speller\n",
    "from nltk.stem import PorterStemmer\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1b7ad47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>username</th>\n",
       "      <th>text</th>\n",
       "      <th>airline_name</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>tweet_location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5.703060e+17</td>\n",
       "      <td>cairdin</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>neutral</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5.703010e+17</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>positive</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5.703010e+17</td>\n",
       "      <td>yvonnalynn</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Lets Play</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5.703010e+17</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>negative</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5.703010e+17</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>negative</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      tweet_id    username  \\\n",
       "0           0  5.703060e+17     cairdin   \n",
       "1           1  5.703010e+17    jnardino   \n",
       "2           2  5.703010e+17  yvonnalynn   \n",
       "3           3  5.703010e+17    jnardino   \n",
       "4           4  5.703010e+17    jnardino   \n",
       "\n",
       "                                                text    airline_name  \\\n",
       "0                @VirginAmerica What @dhepburn said.  Virgin America   \n",
       "1  @VirginAmerica plus you've added commercials t...  Virgin America   \n",
       "2  @VirginAmerica I didn't today... Must mean I n...  Virgin America   \n",
       "3  @VirginAmerica it's really aggressive to blast...  Virgin America   \n",
       "4  @VirginAmerica and it's a really big bad thing...  Virgin America   \n",
       "\n",
       "  airline_sentiment tweet_location  \n",
       "0           neutral            NaN  \n",
       "1          positive            NaN  \n",
       "2           neutral      Lets Play  \n",
       "3          negative            NaN  \n",
       "4          negative            NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading all the fetched data to pandas dataframe\n",
    "df = pd.read_csv('final_train_df.csv',encoding = \"ISO-8859-1\")\n",
    "\n",
    "# Shuffling \n",
    "df_shuffled=df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1230c7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_df = df[df['airline_sentiment']=='positive']\n",
    "neutral_df = df[df['airline_sentiment']=='neutral']\n",
    "negative_df = df[df['airline_sentiment']=='negative']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68bfbf30",
   "metadata": {},
   "source": [
    "### Initial pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41e63205",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>text</th>\n",
       "      <th>airline_name</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>tweet_location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cairdin</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>neutral</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jnardino</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>positive</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yvonnalynn</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Lets Play</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jnardino</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>negative</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jnardino</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>negative</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     username                                               text  \\\n",
       "0     cairdin                @VirginAmerica What @dhepburn said.   \n",
       "1    jnardino  @VirginAmerica plus you've added commercials t...   \n",
       "2  yvonnalynn  @VirginAmerica I didn't today... Must mean I n...   \n",
       "3    jnardino  @VirginAmerica it's really aggressive to blast...   \n",
       "4    jnardino  @VirginAmerica and it's a really big bad thing...   \n",
       "\n",
       "     airline_name airline_sentiment tweet_location  \n",
       "0  Virgin America           neutral            NaN  \n",
       "1  Virgin America          positive            NaN  \n",
       "2  Virgin America           neutral      Lets Play  \n",
       "3  Virgin America          negative            NaN  \n",
       "4  Virgin America          negative            NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropping duplicate tweets\n",
    "df = df.drop_duplicates(['text'])\n",
    "\n",
    "if 'Unnamed: 0' and 'tweet_id' in df.columns: \n",
    "    df = df.drop(['Unnamed: 0','tweet_id'],axis = 1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca3a78a",
   "metadata": {},
   "source": [
    "### Removing special characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1863dcc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                  @VirginAmerica What @dhepburn said.\n",
       "1    @VirginAmerica plus you've added commercials t...\n",
       "2    @VirginAmerica I didn't today... Must mean I n...\n",
       "3    @VirginAmerica it's really aggressive to blast...\n",
       "4    @VirginAmerica and it's a really big bad thing...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean(txt):\n",
    "    txt = txt.replace(\"()\", \"\")\n",
    "    txt = txt.replace('(<a).*(>).*()', '')\n",
    "    txt = txt.replace('(&amp)', '')\n",
    "    txt = txt.replace('(&gt)', '')\n",
    "    txt = txt.replace('(&lt)', '')\n",
    "    txt = txt.replace('(\\xa0)', ' ')  \n",
    "    return txt\n",
    "\n",
    "df['text'] = df['text'].apply(lambda x: clean(x))\n",
    "df['text'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496e127d",
   "metadata": {},
   "source": [
    "### Extracting all the hastags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0443b0cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]                      12909\n",
       "[DestinationDragons]       70\n",
       "[fail]                     36\n",
       "[usairwaysfail]            21\n",
       "[customerservice]          21\n",
       "                        ...  \n",
       "[peanutsonaplatter]         1\n",
       "[letitgo]                   1\n",
       "[hotlanta]                  1\n",
       "[notmadeofmoney]            1\n",
       "[BlackBerry10]              1\n",
       "Name: tweet_hastags, Length: 1785, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tweet_hastags'] = df['text'].apply(lambda x: re.findall(\"#([a-zA-Z0-9_]{1,50})\", x))\n",
    "df['tweet_hastags'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5245d04a",
   "metadata": {},
   "source": [
    "### Extracting all the mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08063867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[united]                            3370\n",
       "[USAirways]                         2470\n",
       "[AmericanAir]                       2281\n",
       "[SouthwestAir]                      2090\n",
       "[JetBlue]                           1932\n",
       "                                    ... \n",
       "[SouthwestAir, JasonWhitely]           1\n",
       "[SouthwestAir, SwagglikeBean]          1\n",
       "[SouthwestAir, SacIntlAirport]         1\n",
       "[SouthwestAir, DJQ_KC, djimpact]       1\n",
       "[JetBlue, hellobrittNEY_]              1\n",
       "Name: mentions, Length: 1021, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['mentions'] = df['text'].apply(lambda x: re.findall(\"@([a-zA-Z0-9_]{1,50})\", x))\n",
    "df['mentions'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd16596",
   "metadata": {},
   "source": [
    "### Removing hastags and mentions from tweets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a966583",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                          What  said.\n",
       "1     plus you've added commercials to the experien...\n",
       "2     I didn't today... Must mean I need to take an...\n",
       "3     it's really aggressive to blast obnoxious \"en...\n",
       "4             and it's a really big bad thing about it\n",
       "Name: tweets, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_annotation(tweet):\n",
    "    clean_tweet = re.sub(\"@[A-Za-z0-9_]+\",\"\", tweet)\n",
    "    clean_tweet = re.sub(\"#[A-Za-z0-9_]+\",\"\", clean_tweet)\n",
    "    return clean_tweet\n",
    "\n",
    "df['tweets'] = df['text'].apply(lambda x: clean_annotation(x))\n",
    "df['tweets'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7908953c",
   "metadata": {},
   "source": [
    "### Removing HTTP Links "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3031511e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                          What  said.\n",
       "1     plus you've added commercials to the experien...\n",
       "2     I didn't today... Must mean I need to take an...\n",
       "3     it's really aggressive to blast obnoxious \"en...\n",
       "4             and it's a really big bad thing about it\n",
       "Name: tweets, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tweets'] = df['tweets'].apply(lambda x: re.sub(r'https?:\\/\\/\\S*', '', x, flags=re.MULTILINE))\n",
    "df['tweets'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a3e111",
   "metadata": {},
   "source": [
    "### Converting to Lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ea59740",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                           what said.\n",
       "1    plus you've added commercials to the experienc...\n",
       "2    i didn't today... must mean i need to take ano...\n",
       "3    it's really aggressive to blast obnoxious \"ent...\n",
       "4             and it's a really big bad thing about it\n",
       "Name: tweets, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tweets'] = df['tweets'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "df['tweets'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e30862a",
   "metadata": {},
   "source": [
    "### Removing punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76ab8874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                            what said\n",
       "1    plus youve added commercials to the experience...\n",
       "2    i didnt today must mean i need to take another...\n",
       "3    its really aggressive to blast obnoxious enter...\n",
       "4              and its a really big bad thing about it\n",
       "Name: tweets, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tweets'] = df['tweets'].str.replace('[^\\w\\s]','')\n",
    "df['tweets'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca6812a",
   "metadata": {},
   "source": [
    "### De-emojify tweets to sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20b1bc14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open(\"../LDA/emoji_regex.txt\", \"r\")\n",
    "def remove_emoji(text):\n",
    "    emoji_pattern = re.compile(f.read(), flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c5176a4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                            what said\n",
       "1    plus youve added commercials to the experience...\n",
       "2    i didnt today must mean i need to take another...\n",
       "3    its really aggressive to blast obnoxious enter...\n",
       "4              and its a really big bad thing about it\n",
       "Name: tweets, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tweets'] = df['tweets'].apply(lambda x: remove_emoji(x))\n",
    "df['tweets'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df413c6d",
   "metadata": {},
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea7c028f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "load_model = spacy.load('en_core_web_sm', disable = ['parser','ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f02cddec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(x):\n",
    "    doc = load_model(x)\n",
    "    return \" \".join([token.lemma_ for token in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a6e383b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                             what say\n",
       "1    plus you ve add commercial to the experience t...\n",
       "2    I do not today must mean I need to take anothe...\n",
       "3    its really aggressive to blast obnoxious enter...\n",
       "4              and its a really big bad thing about it\n",
       "Name: tweets, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tweets'] = df['tweets'].apply(lambda x: lemmatize(x))\n",
    "df['tweets'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e273d6",
   "metadata": {},
   "source": [
    "### Part of speech tagging (POS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "198f5c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "def pos_tag(x):\n",
    "    result = TextBlob(x)\n",
    "    return result.tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7fae17ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m textblob.download_corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "519814df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                             [(what, WP), (say, VBP)]\n",
       "1    [(plus, CC), (you, PRP), (ve, VBP), (add, VB),...\n",
       "2    [(I, PRP), (do, VBP), (not, RB), (today, NN), ...\n",
       "3    [(its, PRP$), (really, RB), (aggressive, JJ), ...\n",
       "4    [(and, CC), (its, PRP$), (a, DT), (really, RB)...\n",
       "Name: tweets_tags, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tweets_tags'] = df['tweets'].apply(lambda x: pos_tag(x))\n",
    "df['tweets_tags'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c32d11",
   "metadata": {},
   "source": [
    "### Named Entity recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f4db7532",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ner(x):\n",
    "    wr = word_tokenize(x)\n",
    "    r = \"\".join(pos_tag(wr))\n",
    "    return ne_chunk(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f2f5743e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['ner_tweets'] = df['tweets'].apply(lambda x: ner(x))\n",
    "# df['ner_tweets'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13085d1d",
   "metadata": {},
   "source": [
    "### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8d4255b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                             what say\n",
       "1          plu you ve add commerci to the experi tacki\n",
       "2    i do not today must mean i need to take anoth ...\n",
       "3    it realli aggress to blast obnoxi entertain in...\n",
       "4               and it a realli big bad thing about it\n",
       "Name: tweets, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemming = PorterStemmer()\n",
    "df['tweets'] = df['tweets'].apply(lambda x: \" \".join([stemming.stem(word) for word in x.split()]))\n",
    "df['tweets'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4537b2c7",
   "metadata": {},
   "source": [
    "### Spell Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "669eef61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spell_check(x):\n",
    "    check = Speller(lang='en')\n",
    "    return check(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9aa1e6b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                             what say\n",
       "1            pl you ve add commerce to the expert tack\n",
       "2     i do not today must mean i need to take not trip\n",
       "3    it really address to blast obnoxi entertain in...\n",
       "4               and it a really big bad thing about it\n",
       "Name: tweets, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tweets'] = df['tweets'].apply(lambda x: spell_check(x))\n",
    "df['tweets'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "47661526",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('final_df.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
